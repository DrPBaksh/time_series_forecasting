{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "251ae905-14fd-461c-b843-9f8c57890041",
   "metadata": {},
   "source": [
    "<!-- <table>\n",
    "  <tr>\n",
    "    <td><img src=\"https://raw.githubusercontent.com/DrPBaksh/image_processing/main/logos/logo_2.png?raw=true\" alt=\"Corndel\" width=\"301.5\" height=\"216\"></td>\n",
    "    <td><img src=\"https://github.com/CorndelDataAnalyticsDiploma/workshop/blob/master/Corndel%20Digital%20Logo%20Centre.png?raw=true\" alt=\"Corndel\" width=\"301.5\" height=\"216\"></td>\n",
    "  </tr>\n",
    "</table> -->\n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/DrPBaksh/image_processing/main/logos/logo_2.png?raw=true\" alt=\"Corndel\" width =\"301.5\" height=216>\n",
    "\n",
    "<!-- <img src=\"https://github.com/CorndelDataAnalyticsDiploma/workshop/blob/master/Corndel%20Digital%20Logo%20Centre.png?raw=true\" alt=\"Corndel\" width =\"301.5\" height=216> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a1f651-c1a0-454d-a670-e06af1379624",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Time Series Forecasting 3 : Exercises : Practise on a different dataset\n",
    "\n",
    "This notebook is a brief version of the main time series forecasting 3 notebook with gaps to fill out in order to apply time series forecasting to some new datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a302e55c-8c81-4cf6-81af-36677011393a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsmodels.graphics import tsaplots \n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import statsmodels.api as sm\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2310de8-59a7-4a7a-a689-1899abb0da52",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Read in the data for the file , data_month. I have hosted it on my github so you need to paste in the following link in as a string and it will pull the csv from there. \n",
    "    \n",
    "\"https://github.com/DrPBaksh/workshop-data/blob/main/data_month.csv?raw=true\" \n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fec9030a-a4e1-411d-a291-b315fe7c649a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"......................\" )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee574514-6eee-4652-b889-44dbfd67e462",
   "metadata": {},
   "source": [
    "**Both ETS and Arima in Python require that the datetime component is in the index of the dataframe**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468cf237-60bf-4a77-a186-fd4300fef64f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Change the Date column to be a pandas datetime datatype. After that set the index as the Date. Rember to use the inplace argument to overwrite the df\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb783d58-124c-4e00-a8ef-3aca85f8e2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Date = pd.to_datetime(df['..........'])\n",
    "df.set_index('..........', inplace = ............)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee62febd-fad3-488e-ad27-a290b569ac14",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "View the data. Insert the correct string into y\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba7fc02f-5155-49f4-b3b8-ff85a25ac3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(y = '..............')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(30, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1a1079-dd30-4c70-83d1-d31440e1a3c9",
   "metadata": {},
   "source": [
    "**Set the frequency of the dataframe. Remember if this errors it indicates you have an incomplete time series**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7788f249-301e-4da8-80b7-3d4ff0c464ab",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "From viewing the data earlier set the correct frequency for the index \n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "072cde07-7678-4dde-9004-7ffd445445e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.freq = '.........'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204916f6-bf99-436e-8160-95efad10eab3",
   "metadata": {},
   "source": [
    "**Split the data into Training and Testing sets**\n",
    "\n",
    "In time series we do this by time and not by random samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb09df0-0761-4ed2-bc9a-b6357613c52f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "We want the training data to include everything up to and including the year 2020. We want the training data to be everything from 2021 onwards\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f520e41d-490a-4489-bb1f-9a602da079dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.loc[:'.......']\n",
    "test = df.loc['........']\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "plt.plot(train.index, train.values)\n",
    "plt.plot(test.index, test.values)\n",
    "plt.legend(['train', 'test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2fc6cc-d33e-4141-a17b-528bf2b3cc54",
   "metadata": {},
   "source": [
    "**Apply Seasonal Decomposition on your data - Remember look at the residual to see if there is any structure left in your data. If there is try a different model or it could be there is a further seasonality**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f8294d-9ac2-4c20-84d0-f60fff01fcbc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Lets have a quick look at the seasonal decomposition. Remember to pass in the correct column of the data frame. Either use a mul or add model. Evaluate which is most appropriate \n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f96ee007-508e-4068-8454-2aa2925c90d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp=seasonal_decompose(train['............'],model='..........')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7a71701-8d35-462a-894c-d0606c0135a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = decomp.plot()\n",
    "fig.set_size_inches((12, 5))\n",
    "fig.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517ee34d-cc4b-444d-b450-cd5f81b1b92a",
   "metadata": {},
   "source": [
    "## Identifying the Period of Seasonality\n",
    "\n",
    "**ACF and PCF**\n",
    "\n",
    "Now that we have the trend identified in the data we can removed the trend to obtan infomation on seasonal features. Both the ACF and PCF can show this \n",
    "\n",
    "The Autocorrelation Function (ACF) and the Partial Autocorrelation Function (PACF) are tools used in time series analysis to identify the underlying structure of the data. Both are used to determine the degree of correlation between a time series and its past values. The ACF measures the correlation between a time series and its lagged values, while the PACF measures the correlation between a time series and its lagged values after accounting for the effect of all the intermediate lags. In other words, the PACF shows the direct effect of each lag on the current value, while the ACF shows the cumulative effect of all lags up to that point.\n",
    "\n",
    "Another way of looking at this is the ACF takes the data at a lag time t and plots that against itself.\n",
    "\n",
    "However the pcf will perform a regression in time where it looks to see how well data at t = 0 correlates with t = t including all the points between t = 0 and t = t. It therefore can be more sensitive to the specific correlation after a number of lags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025533c8-0659-4234-9e26-59795c40f950",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Create a dataframe called detrended. The columns will be date taken from the index of the training data and the values will be a list called detrended taken from the decomp of the observed values and the trend values. Set the index as date. Drop the null values afterwards and view the plot\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f881ede-7636-4957-862f-d0b4d4a244f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "detrended = pd.DataFrame({'.........' : train.index, '..........': decomp.observed.values -decomp.trend.values}).set_index('date')\n",
    "detrended = detrended.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93a549c8-5ff1-4205-b24e-37b1f477eef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12,8))\n",
    "plot_acf(detrended, ax=ax1, lags=15)\n",
    "plot_pacf(detrended, ax=ax2, lags=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa71c2f-887d-4ac1-852a-6d6d0f4e4a07",
   "metadata": {},
   "source": [
    "**For now we shall just look at the ACF that shows a period of 12 lags.  Lets now plot the ETS model remebering that after a grid search from the previous workshop we found the Error was mul, the Trend was add and the seasonal mul. We are going to be working with a variety of models so we shall create a dataframe to store out results so we can make quantitive comparision. Below we have some code that will calculate varipus metrics on our training and testing data and provide a results dataframe.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93254ee2-937e-461c-9b90-93f94e33b69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_results(model_name, data_name, results, train, train_fit, test, test_forecast):\n",
    "    try:\n",
    "        res = {}\n",
    "        res['train_rmse'] = [np.sqrt(np.mean((train.values - train_fit.values)**2)).round(2)]\n",
    "        res['test_rmse'] = [np.sqrt(np.mean((test.values - test_forecast.values)**2)).round(2)]\n",
    "        res['train_mape'] = [100*metrics.mean_absolute_percentage_error(train, train_fit).round(2)]\n",
    "        res['test_mape'] = [100*metrics.mean_absolute_percentage_error(test, test_forecast).round(2)]\n",
    "        res['train_r2'] = [metrics.r2_score(train, train_fit).round(2)]\n",
    "        res['test_r2'] = [metrics.r2_score(test, test_forecast).round(2)]\n",
    "        res['model'] = [model_name]\n",
    "        res['data'] = [data_name]\n",
    "        results = pd.concat([results, pd.DataFrame(res)])\n",
    "    except:\n",
    "        res['train_rmse'] = [np.sqrt(np.mean((train.values - train_fit)**2)).round(2)]\n",
    "        res['test_rmse'] = [np.sqrt(np.mean((test.values - test_forecast)**2)).round(2)]\n",
    "        res['train_mape'] = [100*metrics.mean_absolute_percentage_error(train, train_fit).round(2)]\n",
    "        res['test_mape'] = [100*metrics.mean_absolute_percentage_error(test, test_forecast).round(2)]\n",
    "        res['train_r2'] = [metrics.r2_score(train, train_fit).round(2)]\n",
    "        res['test_r2'] = [metrics.r2_score(test, test_forecast).round(2)]\n",
    "        res['model'] = [model_name]\n",
    "        res['data'] = [data_name]\n",
    "        results = pd.concat([results, pd.DataFrame(res)])\n",
    "        \n",
    "    return results\n",
    "\n",
    "results = pd.DataFrame(columns = ['model', 'data', 'train_rmse', 'train_mape', 'train_r2', 'test_rmse', 'test_mape', 'test_r2'])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db45b42-59d2-4ca4-bf2f-5d285c8a3715",
   "metadata": {},
   "source": [
    "**Create ets model to make predictions on airline passenger data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6197a70-e2d1-4e61-b6d7-08fee4505df6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Below we are training an ETS model. From the previous workshop you can take the best params for this dataset, or use the ones I have. Set the correct number of periods\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6d35c8a-9b57-4d34-b8fe-92f79762faf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= sm.tsa.ETSModel(train['............'].astype('float64'),\n",
    "                                error='mul',          # CHANGE THIS TO BE add or mul          \n",
    "                                trend='mul',          # CHANGE THIS TO BE add or mul\n",
    "                                damped_trend=True,   # CHANGE THIS TO BE True or False\n",
    "                                seasonal='mul',       # CHANGE THIS TO BE add or mul\n",
    "                                seasonal_periods=.......,\n",
    "                                freq='........').fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9385a5a-f3ab-4fa7-b217-e0c4f26cea53",
   "metadata": {},
   "source": [
    "**Take time to understand the next block of code because we repeat this numerous times**\n",
    "\n",
    "- trian_fit_ets is the fitted values of the algorithm over the training data\n",
    "- train_forecast_ets is the models forecast into the future beyond the training data. We are going to forecast data the length of the testing data\n",
    "- the update results function takes the orignal data, train and test in this case the the fitted results and the forecast results and it calculates the RMSE, MAPE and R2 for this model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96187910-b2e8-440f-a0dd-db5d569d57ef",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Adjust the code below so that the first argument to update results is a description of the model that has been trained, e.g ETS and the second is a description of the data we trained it on\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d3c6a72-f93e-4cbe-ab45-757342bbfee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fit_ets = model.fittedvalues\n",
    "test_forecast_ets = model.forecast(steps = len(test))\n",
    "results = update_results('.......', '...........',results, train, train_fit_ets, test, test_forecast_ets)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350f1c59-24c4-4f41-801a-da0f99b03430",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "View the forecast. Ensure you select the correct column to view the forecast with \n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb83b41-182c-4082-9ef3-723192915b4c",
   "metadata": {},
   "source": [
    "**We now have our first result. Lets visualise what is going on in the forecast**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93564eff-b479-441f-a005-80ef8a763772",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train.index, train['..........'])\n",
    "plt.plot(train.index, train_fit_ets, '--')\n",
    "plt.plot(test.index, test['..........'])\n",
    "plt.plot(test.index, test_forecast_ets, '--')\n",
    "plt.legend(['train', 'train_fit', 'test', 'test_forecast'])\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(20, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9889e7-dbf7-4f55-9788-952f137b989a",
   "metadata": {},
   "source": [
    "## ARMA ARIMA SARIMA SARIMAMAX\n",
    "\n",
    "We shall now look to use one of the ARIMA models to make a forecast on this data. There are numerous ARIMA models we can use. I have notebooks that go through each of them however we shall look at where each model shall be used\n",
    "\n",
    "- ARMA: Autoregressive Moving Average. It is a model that uses a combination of autoregressive (AR) and moving average (MA) terms to explain the behavior of a time series. Data most be stationary\n",
    "- ARIMA: Autoregressive Integrated Moving Average. It is a model that extends ARMA by incorporating the concept of differencing to handle non-stationary time series data.\n",
    "- SARIMA: Seasonal Autoregressive Integrated Moving Average. It is an extension of ARIMA that incorporates seasonality in the data.\n",
    "- SARIMAX: Seasonal Autoregressive Integrated Moving Average with Exogenous Variables. It is an extension of SARIMA that allows for the inclusion of exogenous variables to explain the behavior of a time series.\n",
    "\n",
    "How does our air passenger data fit in ?\n",
    "\n",
    "- It is not stationary\n",
    "- It is seasonal\n",
    "- It does not have exogenous variables \n",
    "\n",
    "SARIMA would be most appropriate because of the strong seasonality however lets start with ARIMA model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaedaa5f-ac16-4125-ab00-14defede08cc",
   "metadata": {},
   "source": [
    "### Optimising ARIMA Params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808ba315-6fda-47bc-b911-2d99fd605409",
   "metadata": {},
   "source": [
    "ARIMA has the following Parameters \n",
    "\n",
    "- p: the number of lag observations included in the model, also known as the autoregressive (AR) order.\n",
    "- d: the degree of differencing (the number of times the data have had past values subtracted).\n",
    "- q: the size of the moving average (MA) window.\n",
    "\n",
    "These parameters are used to model the autocorrelation structure of the time series, capturing the relationship between each observation and its lags and seasonality. By selecting appropriate values for these parameters, the ARIMA model can accurately capture the patterns and trends in the time series data, making it useful for forecasting future values.\n",
    "\n",
    "We can estimate the coefficients below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5945c668-4ec8-40b2-be5e-57ea374cef3c",
   "metadata": {},
   "source": [
    "**Step 1: Check for Stationary**\n",
    "The augmented Dickey-Fuller test tests if a time series is stationary. If the p value is greated than 0.05 it means we reject the null hypothosis which is that the dat is stationary and we accept the alternative hypothosis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b40ce8-2c51-4e48-9130-74d83b03d9a3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "We are conducting a test below to see if our data is stationary or not. Be sure to adjust it to the column we are interested in\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7220888c-f830-47bc-b778-7135b6a3516a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "result = adfuller(df['.............'])\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])\n",
    "print('Critical Values:')\n",
    "for key, value in result[4].items():\n",
    "  print('\\t%s: %.3f' % (key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fc9602-ae37-4e86-ab0b-58739c9e12b2",
   "metadata": {},
   "source": [
    "**Step 2: If non stationary - make stationary**\n",
    " In the ARIMA model the d reprents the value required to make the data stationary. We can explore this by looking at the difference between datapoints. See below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb7173a-ae11-4e8d-8ce0-878043658176",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "You need to set this up to use the correct columns\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a757bc24-f7dd-4992-8532-60b345d45210",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(3)\n",
    "ax1.plot(train['............']);\n",
    "ax1.set_title('Original Series'); \n",
    "ax1.axes.xaxis.set_visible(False)\n",
    "# 1st Differencing\n",
    "ax2.plot(train['.............'].diff()); \n",
    "ax2.set_title('1st Order Differencing'); \n",
    "ax2.axes.xaxis.set_visible(False)\n",
    "# 2nd Differencing\n",
    "ax3.plot(train['.............'].diff());\n",
    "ax3.set_title('2nd Order Differencing')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe82c8e4-55a9-4cfc-bf4f-f0c824e834f4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Ensure you are adjusting the code to select the correct column from train \n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ee31ec5-3b21-4fee-8f1d-a85e8721dde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3)\n",
    "plot_acf(train['.............'], ax=ax1)\n",
    "plot_acf(train['..............'].diff().dropna(), ax=ax2)\n",
    "plot_acf(train['F................'].diff().diff().dropna(), ax=ax3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b50a1c-3ee5-4853-bce7-3b56edbbe106",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "From the graph above make sure you make a note of the best value for d\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f5031d-dfa9-4306-b341-2ea0ac64e56a",
   "metadata": {},
   "source": [
    "**Step 3: Finding the value of p , the autoregressive order**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8d0a16-67c9-4fe8-a3ca-dec9b1a658bd",
   "metadata": {},
   "source": [
    "We shall use the PACF function in order to get p. This represents the order of previous data points that we want in order to predict the next data point. Lets look at this for our data. Notice how we are applying the pcf to the detrended data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068ad25a-1c30-4dd5-ac1d-788cc9919d23",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Select the correct column\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "138dafc5-7eeb-4057-9679-909920c84276",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pacf(train['...............'].diff().dropna())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c8c6ed-da8f-4b6f-bb0f-8564591bddd9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "From the graph above make a note for the best value of p\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a57da01-a51c-4395-aa6a-9ddc11b4c390",
   "metadata": {},
   "source": [
    "**Step 4 : calculating q**\n",
    "\n",
    "The moving average part of the coefficents can be calculated from the ACF. Our value of q should be equl to the number of points that fall outside the zone of insignificance. However we should be looking at quite significant spikes and ignore the seaosonal spike. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d2eae2-a5de-4213-8927-c1dbb397011b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Select the correct column\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d74b3697-03c6-4382-bd39-a55e89083291",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(train['................'].diff().dropna())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2389bc3-6dd5-4309-b82b-dc25122e1b28",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Make a note for an approriate value of q\n",
    "<br>\n",
    "</div>\n",
    "**We now fit our ARIMA model to the data we have in train specifying the values for p q and d**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea79ba1-f9ed-4f19-8586-2a1d0e93df34",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Fit the arima model with the correct column and the estimation for p d and q\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa95b6d6-9890-48ee-8a67-0208122c7a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "model = ARIMA(train['..................'], order = (...,...,...))\n",
    "model_fit = model.fit()\n",
    "model_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8243f8e-3d4a-45bd-bbc9-4bef20a72c77",
   "metadata": {},
   "source": [
    "**We shall not look to deeply into the summary apart from to note that the AIC can be used as a measure of how well the model fits the data and that the number of coefficients will depend on the settings for the number of moving average and autoregressive components that you included in the model.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca67c160-70ad-4eab-96b0-2360f70c46fa",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Store the results in the dataframe. Update the description of the model and the data\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93f14770-cb2e-427c-a13b-bc6c09aa688e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fit_arima = model_fit.fittedvalues\n",
    "test_forecast_arima = model_fit.forecast(steps = len(test))\n",
    "results = update_results('........', '...............',results, train, train_fit_arima, test, test_forecast_arima)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b064785f-b09b-4167-8ac2-99c13439bf5f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Adjust the code below to ensure the columns have been updated\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e4fd28e-bb0f-44d5-ad9d-958bdaf5a27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train.index, train['...........'])\n",
    "plt.plot(train.index, train_fit_ets, '--')\n",
    "plt.plot(test.index, test['............'])\n",
    "plt.plot(test.index, test_forecast_ets, '--')\n",
    "plt.plot(train.index, train_fit_arima, '--')\n",
    "plt.plot(test.index, test_forecast_arima, '--')\n",
    "plt.legend(['train', 'train_fit_ets', 'test', 'test_forecast_ets', 'train_fit_ARIMA', 'test_forecats_ARIMA'])\n",
    "# plt.xlim(['1958', '1961'])\n",
    "# plt.ylim([200, 650])\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15 ,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6056109-016a-4854-8ed6-d19b2aaa1447",
   "metadata": {},
   "source": [
    "**Clearly ARIMA is struggling to forecast well without the seasonality component.... This is where SARIMA comes in**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75916ca7-ad6e-4131-9a4d-b79282dc117b",
   "metadata": {},
   "source": [
    "**SARIMA(p,d,q)(P,D,Q)m**\n",
    "\n",
    "SARIMA is the seasonal version of ARIMA that has 3 more coefficients, P, Q, D , m these are the seasonal specific terms for the SARIMA algorithm.\n",
    "\n",
    "- p: the order of the autoregressive (AR) term in an ARIMA model, which represents the dependence of the current value on its previous values.\n",
    "- q: the order of the moving average (MA) term in an ARIMA model, which represents the dependence of the current value on past error terms.\n",
    "- d: the degree of differencing in an ARIMA model, which transforms the non-stationary time series into a stationary one.\n",
    "- P: the order of the seasonal AR term in a SARIMA model, which models the seasonal variation of the time series.\n",
    "- Q: the order of the seasonal MA term in a SARIMA model, which models the seasonal variation of the time series.\n",
    "- D: the degree of seasonal differencing in a SARIMA model, which transforms the seasonal time series into a stationary one.\n",
    "- m: the number of time periods in a seasonal cycle, which is used to identify the period of the seasonal variation in the time series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14eb8654-d8bd-4676-9ea1-d76bc4099bed",
   "metadata": {},
   "source": [
    "**To estimate P Q and D we need to repeat the ARIMA steps for only the seasonal component. Therefore we need to extract the seasonal component first. We can use the decompose function to do this which we saw before. lets see it again**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6dec66-f08c-4b72-9c01-17e5eac97ef7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Adjust the code below for the correct column and choose either a mul or add model \n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77de0b3c-922d-41ed-bc11-0929b901f2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_decompose(train['.............'],model='..........')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46a39135-e186-49d4-908c-12ae9432665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = decomp.plot()\n",
    "fig.set_size_inches((12, 5))\n",
    "fig.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf3beee5-344b-48a2-ab8b-7be8c56ef4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal = decomp.seasonal\n",
    "seasonal.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b892cd3c-31a4-487d-88b1-53c5dfe6906a",
   "metadata": {},
   "source": [
    "Now we have the seasonal component we appy the same steps we did in arima to find p q and d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e204fd-5cd3-4b7c-9d6f-45611d11ae4c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Can you confirm that D = 0\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032a5ed3-e303-4009-88bf-709d5d02cc2f",
   "metadata": {},
   "source": [
    "\n",
    "**Selecting Q**\n",
    "\n",
    "Count the number of lags that are outside the zone of signficance (clearly) of the PCF and the number will be equal to the Q param\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5766e9d2-b10b-4205-b8e8-d7c8c2a02d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pacf(seasonal.diff().dropna(), lags = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f47ca4a-3ba6-4b85-8634-de1caa7915d2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Make a note on the number of signifcant spikes here for Q. This is always a rough estimate\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741fa7cd-e94c-4e65-a3c0-1e04f965c3a8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcef5756-578c-4bae-9c14-6c0074069b58",
   "metadata": {},
   "source": [
    "**Selecting P**\n",
    "\n",
    "Count the number of points that are outside of the zone of signifcance and this will equal the value of p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df5a0674-b30f-4415-a6ae-0657960fd9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(seasonal.diff().dropna(), lags = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9fa004-9a08-47e1-9a2f-981aae616d83",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Make a note of a rough value for P\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20d9db6-574e-4fbe-a110-fbfcca0ff859",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**We now fit our SARIMA model using the coefficients for the seasonality**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1042c6ff-6e84-4e76-ad01-12adad25ce25",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "For the seasonal aarima with the parameters you have identified. \n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e8205d9-3f31-4f2f-8a54-61e8280316af",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 1; p = 1; q = 2; Q =10; P = 6; D = 0; m = 12\n",
    "model = sm.tsa.statespace.SARIMAX(train['..............'], order=(p, d, q), seasonal_order=(P, D, Q, m))\n",
    "model_fit = model.fit()\n",
    "model_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c8ac45-ff21-4960-94e6-35d2a2f0abc3",
   "metadata": {},
   "source": [
    "**Notice far more coefficients that are there to capture the infomation in the seasonality**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adaef87-98ca-49cb-b489-fee7c5833128",
   "metadata": {},
   "source": [
    "**Hopefully you get the idea of what is going on below now. We extract the fitted datapoints, the predictions, analyse them and store them. We then view the plots**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46d29f3-abf2-4f85-be5d-a2f1cb02abf8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Update the results metric table below with an appropriate description for the model and data\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b399937a-5f80-4027-adb0-874c2605edc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fit_sarima = model_fit.fittedvalues\n",
    "test_forecast_sarima = model_fit.forecast(steps = len(test))\n",
    "results = update_results('.........', '.............',results, train, train_fit_sarima, test, test_forecast_sarima)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a660ffaa-03f4-4a1f-b5b4-cdab58756332",
   "metadata": {},
   "source": [
    "**SARIMA looks like an improvement on the ETS algorithm**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50231ea3-a56e-494d-97b5-9095f622beae",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Adjust the plot below so it fits for our new data \n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb520e4e-e593-49c1-b832-c7b7332d80cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train.index, train['..........'])\n",
    "plt.plot(train.index, train_fit_ets, '--')\n",
    "plt.plot(test.index, test['.............'])\n",
    "plt.plot(test.index, test_forecast_ets, '--')\n",
    "plt.plot(train.index, train_fit_arima, '--')\n",
    "plt.plot(test.index, test_forecast_arima, '--')\n",
    "plt.plot(train.index, train_fit_sarima, '--')\n",
    "plt.plot(test.index, test_forecast_sarima, '--')\n",
    "plt.legend(['train', 'train_fit_ets', 'test', 'test_forecast_ets', 'train_fit_ARIMA', 'test_forecats_ARIMA',\n",
    "            'train_fit_SARIMA', 'test_forecats_SARIMA'], loc = 'center left')\n",
    "# plt.xlim([pd.to_datetime('1958-01-01'), pd.to_datetime('1961')])\n",
    "# plt.ylim([200, 650])\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15 ,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec390b0-e13f-4508-9256-bda8c7fc071a",
   "metadata": {},
   "source": [
    "**How important are setting the SARIMA Parameters?**\n",
    "\n",
    "The parameters do effect how the model performs however we have only estimated them. For example lets see the effect when we use seasonal params as Q and P equal to 1 instead. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a163a6-d4c4-4637-a5b2-18cc7e73d16b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Observe the effect of the parameters that you picked. Set P and Q to 1 \n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1d9fbeb-68ad-48d5-b0ef-da138a0d4355",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q =1; P = 1; D = 0; m = 12\n",
    "model = sm.tsa.statespace.SARIMAX(train['.............'], order=(p, d, q), seasonal_order=(P, D, Q, m))\n",
    "model_fit = model.fit()\n",
    "model_fit.summary()\n",
    "train_fit_sarima = model_fit.fittedvalues\n",
    "test_forecast_sarima = model_fit.forecast(steps = len(test))\n",
    "results = update_results('............', '................',results, train, train_fit_sarima, test, test_forecast_sarima)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92223973-ffbd-422b-8d31-9446e8a66616",
   "metadata": {},
   "source": [
    "**Notice we get a slight reduction in the test however the training and testing rmse were worse. In practise we would reccomend that you run a Grid search of a range of values for all your paramters especially p q an P Q. The easiest way to do this would be to run nested for loops cycling through the parameters that you want to try**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba0af9a-a00f-4082-8d35-b0027ebaec07",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Extension </b>\n",
    "ADVANCED : In the cell below set up mutliple nested for loops to run different Sarima Models with different values for p d and q as well as P D and Q. For each iteration store the results and append them to a dataframe. You can use the same update results function we are using here, just change the name\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4ea20b-c485-450b-ab64-9680c492bb99",
   "metadata": {},
   "source": [
    "# Regression Forecasting for More Complicated Time Series\n",
    "\n",
    "ETS and SARIMA model implimentations may struggle when dealing with multiple seasonality. ETS cannot accept multiple seasonal periods , whilst it can detect them it is then prone to overfitting too many seasonal periods. Feel free to try this setting the ETS Seasonal period parameter to None ( we shall use this as a baseline model briefly in our analysis later on).  Alterantively you could manually make many ETS models and combine them to prevent overfitting however this is hard work.  Whilst in theory SARIMA can deal with multiple seasonality in Python in stats models it can't be done with current packages (as far as I am aware). This poses a limitation for time series that have multiple seasonal periods occuring. Furthermore whilst SARIMAMAX can deal with **exogenous** variables (variables that may influence the time series) regression can also do this, and the regresison algorithm will also likely run far quicker. \n",
    "\n",
    "So lets look at the dataset and get into time series forecasting using Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c1845b-7071-4320-a079-01d51e222c0c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Bring in some more complicated data for our rgression analysis.\n",
    "'https://github.com/DrPBaksh/workshop-data/blob/main/bike_counts.csv?raw=true'\n",
    "\n",
    "This data contains the counts of the number of rental bikes that were taking our each hour at a bike sharing compnay. We also have data on the weather and if it was a national holiday\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5289274c-ff8f-4ab1-a902-43549c4c2374",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('...............', parse_dates = True).drop(columns = ['Unnamed: 0'])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "71dd9ada-7c90-4d0d-9c6b-7364b0a8ad75",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "bef151e6-a60b-4df7-bfb9-49009b0bbcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c84a74a-a24b-45b1-bc61-b9f04f59280c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Change the 'Date_Time' column to be a date time datatype\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab91025a-4609-4bc7-807f-a14eb02e8400",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['..........'] = pd.to_datetime(X['............'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "767d9dbe-0925-4db2-80cb-b52f1ac6f2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cea848-f36c-4288-a4ba-f6bb86020b5b",
   "metadata": {},
   "source": [
    "**View the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7443277-7499-4b09-8233-80e0ac65a2d0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "View the data. Ensure you change the columns\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b0659b0-a430-4653-ab7c-b6de08aba167",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.set_index('.............').plot(y = '..............')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(20, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4beb63-8e8e-48ae-92f7-8eec7a9656bc",
   "metadata": {},
   "source": [
    "**The above data was over a long period we could not see what was going on at the day / hour level. We zoom in below**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ff44a7-b7b4-4f3c-81f4-ba7236c44be7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Zoom in on an appropriate time window for the data \n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "533e5e14-aae0-4a52-b4a2-1b7ec48c4195",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.set_index('...........').plot(y = '............')\n",
    "plt.xlim(['.............', '.............'])\n",
    "plt.ylim([0, 300])\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(20, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5af3c6-ad22-4c4f-9b94-a9e1071844a3",
   "metadata": {},
   "source": [
    "**Regression and FB Prophet deal with missing values fine. However ETS and ARIMA do not. It is worth checking and dealing with these missing values if we want to compare models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb620b8a-f56b-410c-8ccf-ff92292e3ebe",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Make the date time column the index\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0d3f81b8-6346-4f47-b930-e9ba908c59fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.set_index('..........')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd633e7-699b-45e0-89a1-6b1a8672bbc8",
   "metadata": {},
   "source": [
    "**Running the cell below should give an error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ef74a90-11be-4292-b4d2-572e18b359e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.index.freq = '............'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba126b8a-09ac-429b-a7bb-4801d438f680",
   "metadata": {},
   "source": [
    "**We can get a better ideas as to what dates are missing by comparing hourly data between two dates with the dates that are in our dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5c1cc89e-c9cd-4ff6-95b2-070d4a6dd45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaps = pd.date_range(start=min(X.index), \n",
    "                     end=max(X.index),\n",
    "                     freq='.......').difference(X.index)\n",
    "gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3c61e951-7b58-49c6-bbfc-be1ff44af8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.index.to_frame().duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a1710a-b2d1-4b05-b56a-99da30b65aa8",
   "metadata": {},
   "source": [
    "**Now lets deal with the missing data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba61d746-440e-4588-a25c-5d5b7f3fcca3",
   "metadata": {},
   "source": [
    "We should impute these missing values. We are first going to create a complete set of dates. We will then merge these clean dates with the exisiting table using a left join. This will leave missing values in this dataframe. We shall then fill these missing values using backfill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbba9176-7a10-4eb0-b7e4-647442f81a8b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "We are creating a new dataframe called cleaned _date. Make sure the column name is called \"Date_Time\"\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dff9a576-a412-4126-b0ac-a0bfde1b1827",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_date = pd.date_range(start=min(X.index), \n",
    "                     end=max(X.index),\n",
    "                     freq='H')\n",
    "X_cleaned = pd.DataFrame(cleaned_date, columns = ['..............'])\n",
    "cleaned_date.shape, X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30f3c38-9707-4892-bb21-7bc318f73de8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Merge the old data with the new cleaned dates dataframe. This will give null values for missing dates. Use the bfill method to impute them \n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5d46cabb-d702-4aa5-9781-4faacbef7037",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleaned = X_cleaned.merge(X, how = '..........', on= '.............')\n",
    "X_cleaned.set_index('Date_Time', inplace = True)\n",
    "X_cleaned = X_cleaned.fillna(method='...........')\n",
    "X_cleaned.index.freq = '.........'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec20442-102f-470d-b7aa-fd018e529277",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleaned.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "376ca920-52ad-4091-bb33-774d7f008950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "acf = plot_acf(X_cleaned['Count'])\n",
    "plt.grid('minor')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e68abe5-f265-4359-b927-ea910218b328",
   "metadata": {},
   "source": [
    "**We observe that there is a strong spike at 24 hours which indicates 24 hour seasonality**\n",
    "\n",
    "We can pull out this 24 hour seasonality from the time series using the decomposition function as shown below. Notice when we plot the trend there is still lots of structure in there. This likely represents the other seasonalities in the time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9fb6703c-074f-4799-a012-24222be9a9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp= sm.tsa.seasonal_decompose(X_cleaned['Count'], period=24, model='add')\n",
    "plt.plot(decomp.seasonal[0:100])\n",
    "plt.title('24 hour seasonality')\n",
    "plt.show()\n",
    "plt.plot(decomp.trend)\n",
    "plt.title('remaining trend')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e075f9-ef50-40e4-84bc-f169219c5f83",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We now want to uncover if there is seasonality at the next level up in time, so we subtract the 24 hour seasonality from the original time series as shown below. We shall also re sample the data to the day level at this point\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f5ea9ead-de6f-4a4c-a64f-2ac28b36d51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "deseasoned_1 = X_cleaned['Count'] - decomp.seasonal\n",
    "\n",
    "\n",
    "\n",
    "acf = plot_acf(deseasoned_1.resample('M').mean())\n",
    "plt.grid(True)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(30, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac28957-bd09-44bc-8e66-48fc609ab89e",
   "metadata": {},
   "source": [
    "**We observe that the autocorrelation seems to peak at between 6 and 7 days which indicates a repeating pattern every week **. Now we can decompose the time series by the week and investigate that for patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a9871a-22bb-4c4d-8a1d-4bc310dc64bb",
   "metadata": {},
   "source": [
    "So finally lets pull out this monthly seasonality based on 365*24 periods "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492e7b7f-38b0-4ec9-b618-984e5e7d1175",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='6'> **Building Regression Model** </a>\n",
    "\n",
    "**Just before we do our regresison model lets extract a baseline model using ETS*\n",
    "- The code below first splits our data into training and testing data and then we fit an ets model\n",
    "- ETS does not allow us to set seasonal periods manually. If we set the seasonal periods to None then ETS tries to fit the best periods for us "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dcaa5c-e45e-483c-b3a4-9fad3cc38d24",
   "metadata": {},
   "source": [
    "**First lets create a train test split for our new data suitable for ets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "29f7bbf8-47cd-4a7d-b2d6-f08a16250283",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.95 #  95 % of the data used for training\n",
    "\n",
    "train= X_cleaned.iloc[:int(len(X) * thresh), :]\n",
    "test= X_cleaned.iloc[int(len(X) * thresh):, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ad0940-3ca5-4ad1-9f27-22dbb43e32de",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Create a baseline ETS model. Ensure you update the results with the correct names. Put the most dominate seasonal periods in. Check you are putting in the correct column name for the column you are trying to predict\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c10ddd33-5cc8-47ce-916d-d5870e55eac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.tsa.ETSModel(train['Count'] ,error='mul', trend= None, seasonal='mul', seasonal_periods=.............).fit()\n",
    "\n",
    "train_fit_ets_2 = model.fittedvalues\n",
    "test_forecast_ets_2 = model.forecast(steps = len(test))\n",
    "results = update_results('...........', '.............',results, train.iloc[:, 0], train_fit_ets_2, test.iloc[:,0], test_forecast_ets_2)\n",
    "# results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4f36ed0c-53e0-4533-bbd4-e324358febc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e046bdb-1ec3-461a-9f6e-30a2553d231b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Update column names \n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "59af70d1-218b-4593-a8c0-91b74fc7ad57",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train.index[-1000:], train['..........'][-1000:])\n",
    "plt.plot(train.index[-1000:], train_fit_ets_2[-1000:], '--')\n",
    "plt.plot(test.index, test['............'])\n",
    "plt.plot(test.index, test_forecast_ets_2, '--')\n",
    "plt.legend(['train_actual', 'train_ets', 'test_atual', 'test_ets'])\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15 ,5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "5b067852-72ec-425c-84f4-5bf2d5156720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.param_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb28cf3-8040-4e2b-af8f-7b4d6f882c75",
   "metadata": {},
   "source": [
    "### Regression Recap\n",
    "\n",
    "In regression we are trying to find a model to predict a dependent variable (in our case total actual load) from one or more independant variables. \n",
    "\n",
    "### What could be influencing our actual load\n",
    "\n",
    "- In our dataset we have the **temperature**. This could be. When considering your problem features external to the time series could definitly be used as a factor to help predict your time series\n",
    "- Time of day : We are seeing fluctuations within a **24 hour period**. This is telling us we need to include time of day in a regression forecast\n",
    "- Day of the week: There looks to be fluctuations in demand depending on the **day of the week**. If this is the case we need to include this as a feature in our predictin\n",
    "- Month of the year : Does the data look to be changing depending on Month? It looks like it is. If we are unsure we can group the data by month and have a look at this?\n",
    "- Year : Is the data changing year by year. If it is this needs to be a feature that we can include in our regression analysis. \n",
    "\n",
    "##### Other variables to consider\n",
    "- lag variables : These are variables that we can create based on, in this case, averages of the load over a period prior to the forecast. These can sometimes be influencial in forecasting\n",
    "- Holiday specific dates : National holidays  are good candidates for these. Depending on the problem there could be other dates around the year that could be included in a regression analysis. For example prediciting holiday bookings will not just be dependant on the seasonal date however there will be a large influence on the school holidays. Having a column that lets the algorithm know if this date is a school holiday or not is likely to improve your forecast signficantly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98980b6c-45ae-4965-86f8-15abe8e246ed",
   "metadata": {},
   "source": [
    "## Prepare the data for regression\n",
    "\n",
    "- We must prepare the data in the same way we prepared data for regression earlier on in the course. So lets immediately split our data, **not randomly but by time again.**\n",
    "- We can seel below total load actual will become our target and temp_mean will become an exogenous variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "ea0c4cae-29e0-410a-aa2f-484a5b5c3d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleaned.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f20357a-0624-406b-8aa6-d63f422e87d3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "y will equal the column you are trying to predict. Update with the correct columns\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9b76297f-0baf-47e5-a03b-e106cd1ffbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X_cleaned['........']\n",
    "X_train = X_cleaned.iloc[:int(len(X) * thresh), :]\n",
    "X_test = X_cleaned.iloc[int(len(X) * thresh):, :]\n",
    "X_train.drop(columns = ['........'], inplace = True)\n",
    "X_test.drop(columns = ['............'], inplace = True)\n",
    "y_train = y[:int(len(X) * thresh)]\n",
    "y_test = y[int(len(X) * thresh):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950b7735-98f0-4348-9310-601cd16da1ed",
   "metadata": {},
   "source": [
    "**Lets visualise what section of our data will be used for both training and for testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95a34af-83af-4a6c-9205-b96737cedff9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Update column names \n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4d4ecaef-c755-4537-a7e5-0e899e326c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 5))\n",
    "y_train.plot(y = '.........')\n",
    "y_test.plot(y = '..........')\n",
    "plt.legend(['training', 'testing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308914d3-5246-437b-987d-479fd1dd5314",
   "metadata": {},
   "source": [
    "**Lets explore whats currently in X_train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "e7487506-83be-4713-b322-59f40c45ce42",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07cea66-ba3e-4dc9-8f80-49d5f6f00cda",
   "metadata": {},
   "source": [
    "## Generating our time features\n",
    "- At the moment regression algorithms cannot work with a timestamp, they require an integer or a float. Therefore we need to break down datetime into its components. Note here you could also be introducing lag variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ecd9860f-8899-44cf-a728-ee486a766c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['year'] = [X_train.index[i].year for i in range(len(X_train))]\n",
    "X_train['month'] = [X_train.index[i].month for i in range(len(X_train))]\n",
    "X_train['time'] = [int(str(X_train.index[i].time())[0:2]) for i in range(len(X_train))]\n",
    "X_train['dayofweek'] = [X_train.index[i].weekday() for i in range(len(X_train))]\n",
    "X_train['weekend'] = np.where(X_train['dayofweek'].isin([5, 6]), 1, 0)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29038776-a76f-408e-9f05-d72badc5c7e6",
   "metadata": {},
   "source": [
    "**Repeat for the testing data so we have the same features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "02f23e94-bb20-4749-98ba-354de0f8df19",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['year'] = [X_test.index[i].year for i in range(len(X_test))]\n",
    "X_test['month'] = [X_test.index[i].month for i in range(len(X_test))]\n",
    "X_test['time'] = [int(str(X_test.index[i].time())[0:2]) for i in range(len(X_test))]\n",
    "X_test['dayofweek'] = [X_test.index[i].weekday() for i in range(len(X_test))]\n",
    "X_test['weekend'] = np.where(X_test['dayofweek'].isin([5, 6]), 1, 0)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d00cc49-5c53-4bb6-aec4-1c714d2d8ef0",
   "metadata": {},
   "source": [
    "## EDA from our regression variables "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376d374d-da94-4826-8a35-b5a1d2034049",
   "metadata": {},
   "source": [
    "Lets quickly graph some of variables to get a better picture of what is going on in this case.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faeb9fd4-02d2-4e7c-aebb-9d1d1ff40913",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Plot the hummidity values against the y train values\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d2822658-d1b1-4fb3-b133-5106bf7a8cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(X_train..............values, y_train.values, color='red', scatter_kws={'color': 'blue', 'alpha': 0.2})\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(X_train.hummidity.values, y_train.values)\n",
    "r_squared = r_value ** 2\n",
    "plt.annotate(f'R2 = {r_squared:.2f}', xy=(0.05, 0.9), xycoords='axes fraction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ac507b-afe3-4f4c-ba36-14d5d831fd67",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b9c0d67-461c-4e9f-aaad-f5120b5ddb4b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Update column names \n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "299d1028-2a89-4db0-906d-03c424bfedfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "columns = ['year', 'month', 'time', 'dayofweek', 'weekend', 'holiday']\n",
    "train_dataset = copy.deepcopy(X_train)\n",
    "train_dataset['target'] = y_train\n",
    "\n",
    "# Iterate over columns and create bar plot with error bars for each\n",
    "for plot_count, col in enumerate(columns):\n",
    "    # Calculate mean and std for unique values in column\n",
    "    col_mean = train_dataset.groupby(col)['target'].mean()\n",
    "    col_std = train_dataset.groupby(col)['target'].std()\n",
    "    plt.subplot(3,2,plot_count + 1)\n",
    "    # Create bar plot with error bars\n",
    "    sns.barplot(x=col_mean.index, y=col_mean.values, yerr=col_std.values)\n",
    "\n",
    "    # Add title and axis labels\n",
    "    plt.title(f'Mean Counts {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('................')\n",
    "\n",
    "    # Show plot\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(20, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d761a7b6-798e-47db-9e86-82e878d37ef4",
   "metadata": {},
   "source": [
    "## Regression Model 1: Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1b0cb5-7979-4c8c-ba83-39e4dfa94ed8",
   "metadata": {},
   "source": [
    "## Training with Date Time Components Only - to compare with ETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "e829b410-babd-461d-a6f9-eabb2fdf2689",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91008840-f903-48fb-873c-2527dff75242",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "train_temp will store our exogenous variables. We will then drop the same variables which we shall use later \n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8ef4ec18-56f4-4e75-bbcf-426048616b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_temp = X_train[['weathersit', 'temp_degrees', 'windspeed_kph', 'hummidity']]\n",
    "X_train = X_train.drop(columns = ['weathersit', 'temp_degrees', 'windspeed_kph', 'hummidity'])\n",
    "test_temp = X_test[['weathersit', 'temp_degrees', 'windspeed_kph', 'hummidity']] # we shall add it on later\n",
    "X_test = X_test.drop(columns = ['weathersit', 'temp_degrees', 'windspeed_kph', 'hummidity'])\n",
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f15567-6a40-45c4-9517-f1a8e8ba356c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Run the LR model\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3f6ead6e-24e9-4829-a380-38dd4fedc69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(............., sm.add_constant(................values),missing='raise').fit()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11ca098-9a7a-4a42-af74-93314206b70f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Update the results and names and date range \n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "34a507e3-ffe2-4db9-8441-1db2d337f3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fit_lr = model.predict(sm.add_constant(X_train))\n",
    "test_forecast_lr =  model.predict(sm.add_constant(X_test, has_constant = 'add'))\n",
    "results = update_results('..........', '............',results, y_train, train_fit_lr, y_test, test_forecast_lr)\n",
    "results\n",
    "\n",
    "plt.plot(y_train.index[-1000:], y_train[-1000:])\n",
    "plt.plot(y_train.index[-1000:], train_fit_lr[-1000:], '--')\n",
    "plt.plot(y_test.index, y_test)\n",
    "plt.plot(y_test.index, test_forecast_lr, '--')\n",
    "plt.legend(['Actual_train', 'lr_train_fit', 'actual test', 'lr_forecast'])\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15 ,5)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(y_test.index, y_test)\n",
    "plt.plot(y_test.index, test_forecast_lr, '--')\n",
    "plt.xlim([pd.to_datetime('................'), pd.to_datetime('.............')])\n",
    "plt.legend(['Actual', 'lr'])\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15 ,5)\n",
    "plt.show()\n",
    "\n",
    "results.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de950f3-a1bc-4998-a8ef-399a2d0c0a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "[100*metrics.mean_absolute_percentage_error(y_train, train_fit_ets_2).round(2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f58a7a5-c169-4047-912f-1150c12759c8",
   "metadata": {},
   "source": [
    "**Notice the linear behaviour in hour. The linear model cant fit to the data the way we have presented the data to it. The linear model can only fit linear trends, unless we one hot encode these columns. Lets see the effect of this now**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6b852e21-5a3b-4d4b-867a-ce62df534812",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "columns_to_encode = ['month', 'time', 'dayofweek']\n",
    "\n",
    "encoder = OneHotEncoder(categories='auto', sparse=False, drop='first').fit(X_train[columns_to_encode])\n",
    "\n",
    "# Transform the training and test data\n",
    "X_train_encoded = pd.DataFrame(encoder.transform(X_train[columns_to_encode]))\n",
    "X_test_encoded = pd.DataFrame(encoder.transform(X_test[columns_to_encode]))\n",
    "\n",
    "# Rename the columns in the encoded DataFrames\n",
    "X_train_encoded.columns = encoder.get_feature_names(columns_to_encode)\n",
    "X_test_encoded.columns = encoder.get_feature_names(columns_to_encode)\n",
    "\n",
    "# Print the first few rows of the encoded DataFrames\n",
    "X_train_encoded = pd.concat([X_train.loc[:, ['year', 'weekend']].reset_index(drop = True), X_train_encoded.reset_index(drop = True)],axis = 1)\n",
    "X_test_encoded = pd.concat([X_test.loc[:, ['year', 'weekend']].reset_index(drop = True), X_test_encoded.reset_index(drop = True)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "721c7d40-0ed5-44b4-ac19-78bb69d3ebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab6012e-01de-4348-919b-5bba30b5e9dd",
   "metadata": {},
   "source": [
    "**Notice the shape difference between encoded dataframe and our original dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2671904a-0d03-490a-a12a-c5c157933a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd126815-d2f9-4895-a94c-7426c21f9491",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Train the new LR model\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cdc91dfb-4d2e-4f07-80c6-9ff8e87bf90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(............., sm.add_constant(.....................values),missing='raise').fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41437b0-f3c2-427f-820e-00c78d1d4a94",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Update the results and names and date range \n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "59d48ef9-e356-4319-9614-4bba0f1d839f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fit_lr_2 = model.predict(sm.add_constant(X_train_encoded))\n",
    "test_forecast_lr_2 =  model.predict(sm.add_constant(X_test_encoded, has_constant = 'add'))\n",
    "results = update_results('..........', '................',results, y_train, train_fit_lr_2, y_test, test_forecast_lr_2)\n",
    "results\n",
    "\n",
    "plt.plot(y_train.index[-1000:], y_train[-1000:])\n",
    "plt.plot(y_train.index[-1000:], train_fit_lr[-1000:], '--')\n",
    "plt.plot(y_test.index, y_test)\n",
    "plt.plot(y_test.index, test_forecast_lr, '--')\n",
    "plt.plot(y_train.index[-1000:], train_fit_lr_2[-1000:], '--')\n",
    "plt.plot(y_test.index, test_forecast_lr_2, '--')\n",
    "plt.legend(['Actual_train', 'lr_train_fit', 'actual test', 'lr_forecast', 'lr-ohe-train', 'lr-ohe-test'])\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15 ,5)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(y_test.index, y_test)\n",
    "plt.plot(y_test.index, test_forecast_lr, '--')\n",
    "plt.plot(y_test.index, test_forecast_lr_2, '--')\n",
    "plt.xlim([pd.to_datetime('2012-12-01'), pd.to_datetime('2012-12-30')])\n",
    "plt.legend(['Actual', 'lr', 'lr-ohe'])\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15 ,5)\n",
    "plt.show()\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3026663-a5f9-4117-a5ac-0775bbc47223",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Make a comment about where the forecast is not doing well and why. Also thing why the MAPE could be so high.\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b39f360-b33e-4a83-951f-5364fe49dfc2",
   "metadata": {},
   "source": [
    "##  <a id='1'> **Improvement using XGBoost** </a>\n",
    "\n",
    "*XGBoost (eXtreme Gradient Boosting) is a powerful and popular machine learning algorithm used for regression and classification problems. It is an implementation of gradient boosting framework. Gradient boosting is an ensemble method that combines multiple weak models, typically decision trees, to create a stronger model. XGBoost improves upon the traditional gradient boosting algorithm by using a more regularized model formalization to control over-fitting, which gives it better performance.The algorithm works by iteratively training decision tree models on the negative gradient of the loss function of the previous iteration. The decision tree models are trained using the gradient descent algorithm. The final model is a weighted sum of all the decision tree models.The algorithm also includes a built-in regularization term, which helps to reduce overfitting and improve generalization. This is done by introducing a penalty term for the number of terminal nodes in the trees, which is controlled by a parameter called \"gamma\".Additionally, XGBoost includes several other features such as parallel processing, handling missing values, built-in cross-validation, and handling categorical variables. It is widely used in many Kaggle competitions and industry applications because of its high performance, speed and scalability.*\n",
    "\n",
    "Resources about XGBoost regressor\n",
    "- https://xgboost.readthedocs.io/en/stable/python/python_intro.html\n",
    "- https://www.youtube.com/watch?v=OtD8wVaFm6E"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef3c20c-8857-4e46-993f-00380004d28d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Fit XGBoost\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8a1f084f-225f-454c-8a68-215d3d667984",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "model = XGBRegressor()\n",
    "model.fit(........, ...............)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fc52d9-35e0-4347-bdb3-27b054c01e06",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Update the results and predictions\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "04e2cb24-f4f0-4e89-af8c-03770c130c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fit_xgb = model.predict(................)\n",
    "test_forecast_xgb =  model.predict(................)\n",
    "results = update_results('.............', '..............',results, y_train, train_fit_xgb, y_test, test_forecast_xgb)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501defd5-94a2-40f6-b7b7-30ed05b502c9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Update the plots\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "738ed5c4-8808-4daa-9c6b-3c6ac22e9ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_train.index[-1000:], y_train[-1000:])\n",
    "plt.plot(y_train.index[-1000:], train_fit_lr[-1000:], '--')\n",
    "plt.plot(y_test.index, y_test)\n",
    "plt.plot(y_test.index, test_forecast_lr, '--')\n",
    "plt.plot(y_train.index[-1000:], train_fit_lr_2[-1000:], '--')\n",
    "plt.plot(y_test.index, test_forecast_lr_2, '--')\n",
    "plt.plot(y_train.index[-1000:], train_fit_xgb[-1000:], '--')\n",
    "plt.plot(y_test.index, test_forecast_xgb, '--')\n",
    "plt.legend(['Actual_train', 'lr_train_fit', 'actual test', 'lr_forecast', 'lr-ohe-train', 'lr-ohe-test', 'xgb-train', 'xgb-test'])\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15 ,5)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(y_test.index, y_test)\n",
    "plt.plot(y_test.index, test_forecast_lr, '--')\n",
    "plt.plot(y_test.index, test_forecast_lr_2, '--')\n",
    "plt.plot(y_test.index, test_forecast_xgb, '--')\n",
    "plt.xlim([pd.to_datetime('................'), pd.to_datetime('...........')])\n",
    "plt.legend(['Actual', 'lr', 'lr-ohe', 'xgb'])\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15 ,5)\n",
    "plt.show()\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99067497-08be-4800-b200-a663896da13d",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a55ae3-ddbb-4655-9f4d-b2cf65374e70",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Hyper Param Tuning</b> <ul>\n",
    "\n",
    "Xgboost has more parameters we can tune. Lets try hyper parameter tuning XGboost to get an imporvement in performance... maybe. \n",
    "\n",
    "This step can take a while so for the workshop we may leave it out\n",
    "    \n",
    "</ol></div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2be5015-5c82-4af4-8dc2-27b2f5bbfcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'gamma': [0, 0.1, 0.5]}\n",
    "#     'subsample': [0.5, 0.7, 0.9],\n",
    "#     'colsample_bytree': [0.5, 0.7, 0.9],\n",
    "#     'reg_alpha': [0, 0.1, 1],\n",
    "#     'reg_lambda': [0, 0.1, 1]\n",
    "# }\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_encoded, y_train)\n",
    "\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "\n",
    "y_pred = grid_search.best_estimator_.predict(X_test_encoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e44082-3883-4927-9a29-4aa13454a43e",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Skip if tuning not run</b> <ul>\n",
    "\n",
    "We now take the best fitting mode and apply it to our test data and record our metrics\n",
    "    \n",
    "</ol></div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d90b8a-a8d2-4c8a-9357-c8835b040a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fit_xgb_h = grid_search.best_estimator_.predict(X_train_encoded)\n",
    "test_forecast_xgb_h =  grid_search.best_estimator_.predict(X_test_encoded)\n",
    "results = update_results('xgb_hyper_param-OHE', 'energy',results, y_train, train_fit_xgb, y_test, test_forecast_xgb)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be934e2e-7510-4841-b56d-f633f7337ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_train.index[-1000:], y_train[-1000:])\n",
    "plt.plot(y_train.index[-1000:], train_fit_lr[-1000:], '--')\n",
    "plt.plot(y_test.index, y_test)\n",
    "plt.plot(y_test.index, test_forecast_lr, '--')\n",
    "plt.plot(y_train.index[-1000:], train_fit_lr_2[-1000:], '--')\n",
    "plt.plot(y_test.index, test_forecast_lr_2, '--')\n",
    "plt.plot(y_train.index[-1000:], train_fit_xgb[-1000:], '--')\n",
    "plt.plot(y_test.index, test_forecast_xgb, '--')\n",
    "plt.plot(y_train.index[-1000:], train_fit_xgb_h[-1000:], '--')\n",
    "plt.plot(y_test.index, test_forecast_xgb_h, '--')\n",
    "plt.legend(['Actual_train', 'lr_train_fit', 'actual test', 'lr_forecast', 'lr-ohe-train', 'lr-ohe-test', 'xgb-train', 'xgb-test', \n",
    "            'xgb-train-hypertune', 'xgb-test-hypertune'])\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15 ,5)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(y_test.index, y_test)\n",
    "plt.plot(y_test.index, test_forecast_lr, '--')\n",
    "plt.plot(y_test.index, test_forecast_lr_2, '--')\n",
    "plt.plot(y_test.index, test_forecast_xgb, '--')\n",
    "plt.plot(y_test.index, test_forecast_xgb_h, '--')\n",
    "plt.xlim([pd.to_datetime('2018-12-01'), pd.to_datetime('2018-12-20')])\n",
    "plt.legend(['Actual', 'lr', 'lr-ohe', 'xgb', 'xgb-h'])\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15 ,5)\n",
    "plt.show()\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16b9eee-37e8-4653-8921-5ad5ee8a1c4c",
   "metadata": {},
   "source": [
    "## Introduing the exogenous variable to our two best perfomring models\n",
    "- Lets now bring back our mean temperature and observer if that would help with the prediction. Note that if we were forecasting using an exogenous variable we would be using the **forecasted** values of that exogenous variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50247006-15dd-42b8-b455-ef9ea3bce64d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Add the exogenous variables into X_train and X_test\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c60459e8-e248-478e-aacc-80786f0bce6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[['weathersit', 'temp_degrees', 'windspeed_kph', 'hummidity']] = train_temp\n",
    "X_test[[....................]] = test_temp\n",
    "X_train_encoded[['weathersit', 'temp_degrees', 'windspeed_kph', 'hummidity']] = train_temp.values\n",
    "X_test_encoded[..............................]= test_temp.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1149ccac-4f9e-4a6b-afa8-2c4f5518ced5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "The code below ensures variables are floats that should be. Ensure you understand\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bc7d9554-e546-47f7-9a84-679c2d3eacb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_cols = ['temp_degrees', 'windspeed_kph' ,'hummidity']   \n",
    "for i in object_cols:\n",
    "    X_train[i] = X_train[i].astype(float)\n",
    "    X_test[i] = X_test[i].astype(float)\n",
    "    X_train_encoded[i] = X_train_encoded[i].astype(float)\n",
    "    X_test_encoded[i] = X_test_encoded[i].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387d0ca4-ad07-438f-beaf-685a003c1669",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Drop the weather situation column for now. It could be used if you want to encode it !\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "afdbd097-62f1-4db9-aa6e-8b19a78caf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(columns = ['weathersit'], inplace = True)\n",
    "X_test.drop(columns = ['............'], inplace = .............)\n",
    "X_train_encoded.drop(columns = ['............'], inplace = .......)\n",
    "X_test_encoded.drop(columns = ['...........'], inplace = ...........)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9d75a67a-6090-47b8-b73b-71858546e32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(y_train, sm.add_constant(.............values),missing='raise').fit()\n",
    "model.summary()\n",
    "\n",
    "train_fit_lr_3 = model.predict(sm.add_constant(..............)\n",
    "test_forecast_lr_3 =  model.predict(sm.add_constant(............., has_constant = 'add'))\n",
    "results = update_results('...........', '...............',results, y_train, train_fit_lr_3, y_test, test_forecast_lr_3)\n",
    "results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426be63c-8ad9-4b12-98ea-41ed4f9a145e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Fit the XGBoost model wit the new exogenous data\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4c607254-19ad-4737-bf07-b952b179cd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor()\n",
    "model = model.fit(............. y_train)\n",
    "train_fit_xgb_exog = model.predict(............)\n",
    "test_forecast_xgb_exog =  model.predict(X_test_encoded)\n",
    "results = update_results('...........', '............',results, y_train, train_fit_xgb_exog, y_test, test_forecast_xgb_exog)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f696f8a-8705-42f9-ae4c-bd086107aa03",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Plot just the XGBoost result\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8dbb5b6a-75a7-4cc7-896d-665a3dcbfeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.plot(y_test.index, y_test)\n",
    "plt.plot(y_test.index, test_forecast_xgb_exog, '--')\n",
    "plt.xlim([pd.to_datetime('..........'), pd.to_datetime('............')])\n",
    "plt.legend(['Actual' 'xgb'])\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15 ,5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b3a3b1-c697-4bc6-99d4-b3e6b8855134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e95f983-e79c-41be-afce-00f5ab479e07",
   "metadata": {},
   "source": [
    "# Facebook Prophet Time Series Forecasting\n",
    "\n",
    "*Prophet is a very powerful easy to use forecasting algorithm with many paramters to tune to specific business cases. Whilst it tries to autodetect many paramters many paramters can be set for imporved performance*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181edd6a-d915-4752-a527-d05f0102a790",
   "metadata": {},
   "source": [
    "Facebook Prophet is a time-series forecasting library developed by Facebook. It is designed to make it easy for analysts and developers to create accurate forecasts for a wide range of time-series data such as sales, weather, and stock prices. It is based on an additive regression model that incorporates features such as trends, seasonality, and holidays. Prophet also has built-in functionality for handling missing data and outliers. It is widely used in industries such as finance, retail, and healthcare for forecasting and decision-making purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a6802c-578d-404b-b100-8727b33af9e0",
   "metadata": {},
   "source": [
    "Facebook Prophet is a time series forecasting model developed by Facebook that uses a generalized additive model (GAM) to make predictions. It is similar to ARIMA in that it can model time series data with seasonality and trends. However, Prophet has some advantages over ARIMA in terms of ease of use and performance.\n",
    "\n",
    "One advantage of Prophet is that it does not require as much domain knowledge or manual feature engineering as ARIMA, as it can automatically detect and model seasonality and trends. Additionally, Prophet is often faster to train and can handle missing data more easily than ARIMA.\n",
    "\n",
    "That being said, ARIMA is a more traditional and widely used time series forecasting model, and may still be a better choice for certain applications or data sets. It ultimately depends on the specific needs and characteristics of the problem at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b466dee-3062-4cde-b553-48bbbb4aead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8ed6c184-e22d-4e24-91ee-72204df8824e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a8d8b2-83e4-4875-89c0-4978c28da9ca",
   "metadata": {},
   "source": [
    "**Prophet requires a column with datetime format and a column with the variable we need to predict. We shall therefore use train and test the variables we used earlier on (prior to regression)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "73a86101-1789-4ab8-a430-b5ae481e4891",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950785cc-72ac-4f11-b955-8913d6ddbd71",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Reset the index of train and test since prophet needs them as a column \n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44fa32f-d1ba-46cd-a5f2-1f0ab7d4c867",
   "metadata": {},
   "source": [
    "**Prophet needs the date_time as a column and not an index so we shall reset the index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1e8e510d-4934-4f6d-8375-34bd04604450",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(inplace = True)\n",
    "test..........(inplace = ..............)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77ade76-ce69-4e17-8681-9cdcc53c1d80",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Rename the columns for Prophet format\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c381bcc-cbe5-491b-8888-9defb974dba9",
   "metadata": {},
   "source": [
    "**NOTE : Prophet takes a dataframe as its input. It will specifically require that the date component column be caled 'ds'. It specifcally requires the target component to be called 'y'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "77bee854-bded-466b-b34f-dde380f28942",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fb = train\n",
    "train_fb = train_fb.rename(columns = {'Date_Time': 'ds', '.....':'........'})\n",
    "train_fb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "01cadcf2-8294-4769-9fb1-81aa5cd4fc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fb = test\n",
    "test_fb = test_fb.rename(columns = {'.......': '........', '......':'....'})\n",
    "test_fb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c490b94-7702-4797-8434-1688e6819839",
   "metadata": {},
   "source": [
    "**Initially we shall call our model m and fit our data to Prophet with no paramters. Later in this notebook we can go through these parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ec0c31-2548-47e4-812b-38f70e5a1fce",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Fit the model to train_fb\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e251f1bf-30ea-4b00-817a-ba7dd4628b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Prophet()\n",
    "model.fit(...........)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ae51a8-e968-4328-afe0-0a10a7d8ba31",
   "metadata": {},
   "source": [
    "**Once the data is fited to Prophet making a forecast is simple. Be clear to set the frequency of points at which you want your forecast. By default it may not forecast at the frequency of the data you used to train it. Use the same frequency codes you would to set any time series data in pandas. Also note to set the number of forecast periods required**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590e5741-7c57-44c6-9964-34e1e0f40bb3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "View and store the results\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b1658421-b9cb-4917-840b-805d34af2865",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_fit_fb = model.predict(........)\n",
    "test_forecast_fb =  model.predict(t........)\n",
    "results = update_results('....', '.........',results, train_fb.y, train_fit_fb.yhat,test_fb.y, test_forecast_fb.yhat)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a067262-0d91-4586-a5a2-3fe7afb7792a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3cd9fdf8-f9d0-45b5-9141-bd193be81d16",
   "metadata": {},
   "source": [
    "**Lets now see if we can improve our forecast using an exogenous variable, in this case temp_mean**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5d600af0-e6ab-405d-8122-eecf05c673b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fb.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f458948f-bac2-4cec-a480-84941da1d8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_cols = ['temp_degrees', 'windspeed_kph' ,'hummidity']   \n",
    "for i in object_cols:\n",
    "    train_fb[i] = train_fb[i].astype(int)\n",
    "    test_fb[i] = test_fb[i].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30367a9-91f7-43e6-92a8-b99d551a5756",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question </b>\n",
    "Add params to the prophet model. We shall add temp_degrees, hummidity windspeed and holidays. Lets also add yearly seasonality\n",
    " \n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "33c5ebed-291e-47cd-9823-1e8da8691908",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Prophet()\n",
    "model.add_regressor('temp_degrees')\n",
    "model.add_regressor('.........')\n",
    "model.add_regressor('hummidity')\n",
    "model.add_regressor('..........')\n",
    "\n",
    "model.add_seasonality(name='yearly', period=int(........ *24), fourier_order=10)\n",
    "model.fit(train_fb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f08ce6-c1d1-4eef-b622-bbafacdf21a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3d9b6ee4-6103-4e41-ac2f-117e3f5c4c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fit_fb = model.predict(train_fb)\n",
    "test_forecast_fb =  model.predict(test_fb)\n",
    "results = update_results('........', '..........',results, train_fb.y, train_fit_fb.yhat,test_fb.y, test_forecast_fb.yhat)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1cd2ab-8afe-44e5-a9ae-9f0a318f2738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
